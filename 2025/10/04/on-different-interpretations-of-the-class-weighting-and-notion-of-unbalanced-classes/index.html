
<!DOCTYPE html>

<html class="no-js" lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width,initial-scale=1" name="viewport"/>
<link href="../../09/what-is-the-weather-and-can-it-be-predicted/" rel="next"/>
<link href="../../../../assets/images/favicon.png" rel="icon"/>
<meta content="mkdocs-1.6.1, mkdocs-material-9.6.21" name="generator"/>
<title>On different interpretations of the class weighting and notion of unbalanced classes - Kirill Semkin's blog</title>
<link href="../../../../assets/stylesheets/main.2a3383ac.min.css" rel="stylesheet"/>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&amp;display=fallback" rel="stylesheet"/>
<style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
<link href="https://unpkg.com/katex@0/dist/katex.min.css" rel="stylesheet"/>
<script>__md_scope=new URL("../../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
<meta content="website" property="og:type"/>
<meta content="On different interpretations of the class weighting and notion of unbalanced classes - Kirill Semkin's blog" property="og:title"/>
<meta content="None" property="og:description"/>
<meta content="./assets/images/social/posts/unbalanced_classes/unbalanced_classes.png" property="og:image"/>
<meta content="image/png" property="og:image:type"/>
<meta content="1200" property="og:image:width"/>
<meta content="630" property="og:image:height"/>
<meta content="None" property="og:url"/>
<meta content="summary_large_image" name="twitter:card"/>
<meta content="On different interpretations of the class weighting and notion of unbalanced classes - Kirill Semkin's blog" name="twitter:title"/>
<meta content="None" name="twitter:description"/>
<meta content="./assets/images/social/posts/unbalanced_classes/unbalanced_classes.png" name="twitter:image"/>
<script src="https://cdn.plot.ly/plotly-latest.min.js"></script></head>
<body dir="ltr">
<input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/>
<input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/>
<label class="md-overlay" for="__drawer"></label>
<div data-md-component="skip">
<a class="md-skip" href="#on-different-interpretations-of-the-class-weighting-and-notion-of-unbalanced-classes">
          Skip to content
        </a>
</div>
<div data-md-component="announce">
</div>
<header class="md-header md-header--shadow" data-md-component="header">
<nav aria-label="Header" class="md-header__inner md-grid">
<a aria-label="Kirill Semkin's blog" class="md-header__button md-logo" data-md-component="logo" href="../../../.." title="Kirill Semkin's blog">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M17.8 20c-.4 1.2-1.5 2-2.8 2H5c-1.7 0-3-1.3-3-3v-1h12.2c.4 1.2 1.5 2 2.8 2zM19 2c1.7 0 3 1.3 3 3v1h-2V5c0-.6-.4-1-1-1s-1 .4-1 1v13h-1c-.6 0-1-.4-1-1v-1H5V5c0-1.7 1.3-3 3-3zM8 6v2h7V6zm0 4v2h6v-2z"></path></svg>
</a>
<label class="md-header__button md-icon" for="__drawer">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"></path></svg>
</label>
<div class="md-header__title" data-md-component="header-title">
<div class="md-header__ellipsis">
<div class="md-header__topic">
<span class="md-ellipsis">
            Kirill Semkin's blog
          </span>
</div>
<div class="md-header__topic" data-md-component="header-topic">
<span class="md-ellipsis">
            
              On different interpretations of the class weighting and notion of unbalanced classes
            
          </span>
</div>
</div>
</div>
<script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
<div class="md-header__source">
<a class="md-source" data-md-component="source" href="https://github.com/sem-k32/semk-blog" title="Go to repository">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 7.0.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"></path></svg>
</div>
<div class="md-source__repository">
    GitHub
  </div>
</a>
</div>
</nav>
</header>
<div class="md-container" data-md-component="container">
<main class="md-main" data-md-component="main">
<div class="md-main__inner md-grid">
<div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" hidden="">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="Navigation" class="md-nav md-nav--primary" data-md-level="0">
<label class="md-nav__title" for="__drawer">
<a aria-label="Kirill Semkin's blog" class="md-nav__button md-logo" data-md-component="logo" href="../../../.." title="Kirill Semkin's blog">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M17.8 20c-.4 1.2-1.5 2-2.8 2H5c-1.7 0-3-1.3-3-3v-1h12.2c.4 1.2 1.5 2 2.8 2zM19 2c1.7 0 3 1.3 3 3v1h-2V5c0-.6-.4-1-1-1s-1 .4-1 1v13h-1c-.6 0-1-.4-1-1v-1H5V5c0-1.7 1.3-3 3-3zM8 6v2h7V6zm0 4v2h6v-2z"></path></svg>
</a>
    Kirill Semkin's blog
  </label>
<div class="md-nav__source">
<a class="md-source" data-md-component="source" href="https://github.com/sem-k32/semk-blog" title="Go to repository">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 7.0.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"></path></svg>
</div>
<div class="md-source__repository">
    GitHub
  </div>
</a>
</div>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--active">
<a class="md-nav__link" href="../../../..">
<span class="md-ellipsis">
    Welcome to the blog
    
  </span>
</a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="Table of contents" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
<ul class="md-nav__list" data-md-component="toc" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#logistic-regresion-with-unbalanced-classes">
<span class="md-ellipsis">
      Logistic regresion with unbalanced classes
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#do-class-weights-always-help-with-unbalanced-classes">
<span class="md-ellipsis">
      Do class weights always help with unbalanced classes?
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#is-class-imbalance-evil">
<span class="md-ellipsis">
      Is class imbalance evil?
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#conclusion">
<span class="md-ellipsis">
      Conclusion
    </span>
</a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-content md-content--post" data-md-component="content">
<div class="md-sidebar md-sidebar--post" data-md-component="sidebar" data-md-type="navigation">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner md-post">
<nav class="md-nav md-nav--primary">
<div class="md-post__back">
<div class="md-nav__title md-nav__container">
<a class="md-nav__link" href="../../../..">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"></path></svg>
<span class="md-ellipsis">
                    Back to index
                  </span>
</a>
</div>
</div>
<div class="md-post__authors md-typeset">
<div class="md-profile md-post__profile">
<span class="md-author md-author--long">
<img alt="Kirill Semkin" src="https://avatars.githubusercontent.com/u/42578877?s=400&amp;u=ff26e03579920d7616ac2ecbe3df72a02384d105&amp;v=4"/>
</span>
<span class="md-profile__description">
<strong>
                        
                          Kirill Semkin
                        
                      </strong>
<br/>
                      Creator
                    </span>
</div>
</div>
<ul class="md-post__meta md-nav__list">
<li class="md-nav__item md-nav__item--section">
<div class="md-post__title">
<span class="md-ellipsis">
                    Metadata
                  </span>
</div>
<nav class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<div class="md-nav__link">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M19 19H5V8h14m-3-7v2H8V1H6v2H5c-1.11 0-2 .89-2 2v14a2 2 0 0 0 2 2h14a2 2 0 0 0 2-2V5a2 2 0 0 0-2-2h-1V1m-1 11h-5v5h5z"></path></svg>
<time class="md-ellipsis" datetime="2025-10-04 00:00:00+00:00">October 4, 2025</time>
</div>
</li>
<li class="md-nav__item">
<div class="md-nav__link">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 20a8 8 0 0 0 8-8 8 8 0 0 0-8-8 8 8 0 0 0-8 8 8 8 0 0 0 8 8m0-18a10 10 0 0 1 10 10 10 10 0 0 1-10 10C6.47 22 2 17.5 2 12A10 10 0 0 1 12 2m.5 5v5.25l4.5 2.67-.75 1.23L11 13V7z"></path></svg>
<span class="md-ellipsis">
                            
                              7 min read
                            
                          </span>
</div>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</div>
</div>
</div>
<article class="md-content__inner md-typeset">
<div><h1 id="on-different-interpretations-of-the-class-weighting-and-notion-of-unbalanced-classes">On different interpretations of the class weighting and notion of unbalanced classes</h1>
<p><em>Class weighting</em> is often referred to as a simple and powerful technique to use when solving classification problems with <em>unbalanced classes</em>. But how can it be interpreted in a probabilistic sense? We are going to answer it using binary classification problem with the logistic regression model as an example. However, the more general question of the article is actually <em>why unbalanced classes is the issue</em> in the first place? Is it the issue by itself or is it a conseqence of some underlying property of the data? We will figure this out by the course of the narrative.</p>
<!-- more -->
<h2 id="logistic-regresion-with-unbalanced-classes">Logistic regresion with unbalanced classes</h2>
<p>Imagine we have binary classification problem. The <em>logistic regression</em> model defines probabilty of class <span class="arithmatex">\(y = 1\)</span> given object's features <span class="arithmatex">\(x_i\)</span> as</p>
<div class="arithmatex">\[
    p(y = 1 | w, x) = \frac{1}{1 + \exp \big(-\langle w, x \rangle \big)} = \sigma \big( \langle w, x \rangle \big),
\]</div>
<p>where $ \langle w, x \rangle $ is the scalar product, <span class="arithmatex">\(\sigma(\cdot)\)</span> is the sigmoid function. The <span class="arithmatex">\(w\)</span> is the model's parameter vector. It defines the <em>separating</em> hyperplane in the space of <span class="arithmatex">\(x\)</span>. The further you go from this hyperplane to one half-space or another the more probable label <span class="arithmatex">\(1\)</span> or label <span class="arithmatex">\(0\)</span> will be for a given object. The label's probabilities on the line are equal. This is illustrated on the figure below where
    $
    x = \begin{pmatrix}
        x_1 \
        x_2 \
        \end{pmatrix} \in \mathbb{R}^2
    $ 
and 
    $
        w = \begin{pmatrix}
        w_1 \
        w_2 \
            \end{pmatrix} = 
        \begin{pmatrix}
        0 \
        1 \
            \end{pmatrix}
    $.
The color intensity is proportional to $ p(y = 1 | w, x) $.</p>
<div class="mkdocs-plotly" data-jsonpath="../../../../posts/unbalanced_classes/graphs/log_regr.json"></div>
<p>Imagine, we don't know true <span class="arithmatex">\(w\)</span>. Assume we are given the following dataset</p>
<div class="mkdocs-plotly" data-jsonpath="../../../../posts/unbalanced_classes/graphs/dataset.json"></div>
<p>We can see that all objects are quite far from the (true) separation line. Their classes turned out to be the most probable under our model. We also see that the number of points in the upper plane is much less than in the lower. Consequently, we have the <em>dataset with unbalanced classes</em> - class <span class="arithmatex">\(1\)</span> is significantly under-represented relative to class <span class="arithmatex">\(0\)</span>.</p>
<p>When we know true <span class="arithmatex">\(w\)</span>, we understand that this situation does not arise from the initial model <span class="arithmatex">\(p(y|w, x)\)</span> by itself but rather from the positions of the objects in the dataset. Imagine the object were chosen closer to the separation line, then the dataset would be far more likely balanced because the classes' probabilities would be much closer to <span class="arithmatex">\(0.5\)</span>.</p>
<p>But now we are in the situation where we don't know anything about true <span class="arithmatex">\(w\)</span> and how objects were chosen - they were simply given. Should we worry about unbalanced classes? To begin with, let's just find the most probable model for the dataset.</p>
<div class="mkdocs-plotly" data-jsonpath="../../../../posts/unbalanced_classes/graphs/ml_model.json"></div>
<p>We see our estimation is not very close to the truth, even though the sample size is enough to learn such a simple model. It seems that the unbalanced classes are the cause of the problem.</p>
<p>We can deal with the issue using technique called <em>class weights</em>. Before a full explanation, let's just see the magic of it.</p>
<div class="mkdocs-plotly" data-jsonpath="../../../../posts/unbalanced_classes/graphs/ml_model_balanced.json"></div>
<p>So in general, the technique adds custom class weight to every entry of the corresponding class in the loss function. Then the model is estimated using the modified loss. In the case of logistic regression, the regular loss is the negative log-likelihood:</p>
<div class="arithmatex">\[
    L = -\sum_{i=1}^{N} \left[ y_i \log p(y=1|x_i, w) + (1 - y_i) \log p(y=0|x_i, w) \right].
\]</div>
<p>If we weight class 1 with <span class="arithmatex">\(\omega_1 &gt; 0\)</span> and class 0 with <span class="arithmatex">\(\omega_0 &gt; 0\)</span>, the modified loss is:</p>
<div class="arithmatex">\[
    L_{\text{cw}} = - \sum_{i=1}^{N} \left[ \omega_1 \cdot y_i \log p(y=1|x_i, w) + \omega_0 \cdot (1 - y_i) \log p(y=0|x_i, w) \right].
\]</div>
<p>Without loss of generality, we set <span class="arithmatex">\(\omega_0 = 1\)</span>, <span class="arithmatex">\(\omega_1 = \omega\)</span>. Then <span class="arithmatex">\(\omega\)</span> is the indicator of how many times class 1 is more "important" to us than class 0. Let's give several prespectives to interpret the change in the loss.</p>
<ol>
<li>From the <em>optimisation</em> point of view, terms with higher weight now contribute greater to the function increase. Now the optimiser has to give higher probability to the higher weighted class to compensate for this increase through the <span class="arithmatex">\(\log p\)</span> term.</li>
<li>Assume <span class="arithmatex">\(\omega \ge 2\)</span> is a positive integer. Then, by multiplying objects' losses by <span class="arithmatex">\(\omega\)</span> we actually <em>increase the sample size</em> of the weighted class in <span class="arithmatex">\(\omega\)</span> times. Therefore, we directly address the issue of the unbalanced classes by balancing their frequencies in the dataset. If <span class="arithmatex">\(\omega\)</span> is any positive real, then the effect is essentially the same (note that if <span class="arithmatex">\(\omega &lt; 1\)</span> then we increase the sample size of the counter-class).</li>
<li>Change of the loss always leads to the <em>change of the probability model</em> of the data. Let's rewrite the new loss function:</li>
</ol>
<div class="arithmatex">\[
    L_{\text{cw}} = - \sum_{i=1}^{N} \left[ y_i \log p(y=1|x_i, w) + \omega \cdot (1 - y_i) \log p(y=0|x_i, w) \right] = \\ = - \sum_{i=1}^{N} \left[ y_i \log \sigma (\langle w, x_i \rangle) + (1 - y_i) \log (1 - \sigma (\langle w, x_i \rangle))^{\omega} \right].
\]</div>
<p>Now the values under the logarithm do not sum up to one; let's norm them:</p>
<div class="arithmatex">\[
    L_{\text{cw}} = - \sum_{i=1}^{N} [ y_i \log \frac{\sigma (\langle w, x_i \rangle)}{\sigma (\langle w, x_i \rangle) + (1 - \sigma (\langle w, x_i \rangle))^{\omega}} + \\ + (1 - y_i) \log \frac{(1 - \sigma (\langle w, x_i \rangle))^{\omega}}{\sigma (\langle w, x_i \rangle) + (1 - \sigma (\langle w, x_i \rangle))^{\omega}} + \\ + \log \big( \sigma (\langle w, x_i \rangle) + (1 - \sigma (\langle w, x_i \rangle))^{\omega} \big) ] \ge \\ \ge - \sum_{i=1}^{N} \left[ y_i \log \tilde{p}(y=1|x_i, w) + (1 - y_i) \log \tilde{p}(y=0|x_i, w) \right] = \tilde{L}.
\]</div>
<p>We denoted new class probabilities as <span class="arithmatex">\(\tilde{p}\)</span>. When we normed the former probabilities we also had to add a new term $ \log \big( \sigma (\langle w, x \rangle) + (1 - \sigma (\langle w, x \rangle))^{\omega} \big) $. In our primary case of <span class="arithmatex">\(\omega &gt; 1\)</span> this term is nonpositive so the last inequality is valid. What we got at the end is the negative log likelihood <span class="arithmatex">\(\tilde{L}\)</span> of the <em>new model</em> with the class probabilities proportional to <span class="arithmatex">\(p(y=1|x, w)\)</span> and <span class="arithmatex">\(p(y=0|x, w)^{\omega}\)</span>. Hence <span class="arithmatex">\(L_{\text{cw}}\)</span> is the upper bound on <span class="arithmatex">\(\tilde{L}\)</span> and minimising <span class="arithmatex">\(L_{\text{cw}}\)</span> also gives us an estimation of the new model's optimal parameters. The new model is not logistic regression in general.</p>
<p>Overall, we can interpret the situation as follows: we had our initial logistic model but then someone decreased the probability of class <span class="arithmatex">\(0\)</span> and generated the labels with new probabilities.</p>
<p>The decrease of class 0 probability leads to the change of the separation line. We can find its new equation from</p>
<div class="arithmatex">\[
    p(y=0|x, w)^{\omega} = p(y=1|x, w) \\
    \big( 1 - \sigma (\langle w, x \rangle ) \big)^{\omega} = \sigma (\langle w, x \rangle )
\]</div>
<p>This equation has a unique solution for <span class="arithmatex">\(\langle w, x \rangle\)</span> when <span class="arithmatex">\(\omega &gt; 0\)</span> (but cannot be solved analytically in general). Therefore, the separation line will still be a line but shifted towards the less weighted class as we saw from the example above.</p>
<div class="admonition info">
<p class="admonition-title">Info</p>
<p>On practice, the common choice of the weights is to take them proportional to the inverse frequences of the classes. That's what <code>class_weight='balanced'</code> does in some of the sklearn's estimators.</p>
</div>
<h2 id="do-class-weights-always-help-with-unbalanced-classes">Do class weights always help with unbalanced classes?</h2>
<p>Consider the following example under the previous model.</p>
<div class="mkdocs-plotly" data-jsonpath="../../../../posts/unbalanced_classes/graphs/mixed_dataset.json"></div>
<p>So several points of class 1 appeared in the lower half-plane which is possible under the logistic regression. The classes are still unbalanced. Now let's find maximum likelihood estimation (MLE) with and without class weights.</p>
<div class="mkdocs-plotly" data-jsonpath="../../../../posts/unbalanced_classes/graphs/models_comparasion.json"></div>
<p>So we see that using class weights doesn't do a good job here.</p>
<h2 id="is-class-imbalance-evil">Is class imbalance evil?</h2>
<p>To be honest, we can always find examples of the dataset where class weights give better or worse estimation of <span class="arithmatex">\(w\)</span>. The point of the demonstration is different - <em>choose any given method according to the one's assumptions and knowledge about the data</em>. If you are given the dataset with unbalanced classes and have no idea why they are unbalanced, just use MLE and rely on its asymptotic properties. Using class weights in this situation becomes a gamble. But if you have some prior knowledge about data generation, then its incorporation in the loss will be healthy. We have already figured out what it means in the case of the class weights. But the knowledge can be different. For example, along with the given data I could say that the <span class="arithmatex">\(\| w \|\)</span> is small and the second component is closer to zero more probably than the second. This knowledge could be easily transformed into regularising terms on <span class="arithmatex">\(w\)</span> in the loss function. Or I could say that objects <span class="arithmatex">\(x_i\)</span> were actually chosen randomly but with very high probability that their distance to the separation line is some given constant <span class="arithmatex">\(d\)</span> (that's what exactly happened in our demonstration). That is equal to the knowing <span class="arithmatex">\(p(x) = p(x | w, d)\)</span>. Then the full log liklehood of the dataset would be </p>
<div class="arithmatex">\[
    \log p(y, X | w, d) = \log p(X | w, d) + \log p(y| X, w)
\]</div>
<p>and again we would come up with some regularisation of the inital loss.</p>
<h2 id="conclusion">Conclusion</h2>
<p>The issue of unbalanced classes does not exist by itself. Otherwise the balanced classes would be an issue too, wouldn't they? Any pattern in the data should be examined according to some expectations and prior knowledge of the field you're analyzing or anything else connected to the process of obtaining original data. Only then will the incorporation of associated techniques be justified and productive.</p>
<p>The notebook for the article is available at <a href="https://github.com/sem-k32/semk-blog/blob/master/docs/posts/unbalanced_classes/unbalanced_classes.ipynb"><img alt="Python" src="https://img.shields.io/badge/Github-8A2BE2?logo=github"/></a>.</p></div>
</article>
</div>
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
</div>
</main>
<footer class="md-footer">
<div class="md-footer-meta md-typeset">
<div class="md-footer-meta__inner md-grid">
<div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" rel="noopener" target="_blank">
      Material for MkDocs
    </a>
</div>
<div class="md-social">
<a class="md-social__link" href="https://x.com/sem_k32" rel="noopener" target="_blank" title="Twitter account">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 7.0.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M357.2 48h70.6L273.6 224.2 455 464H313L201.7 318.6 74.5 464H3.8l164.9-188.5L-5.2 48h145.6l100.5 132.9zm-24.8 373.8h39.1L119.1 88h-42z"></path></svg>
</a>
<a class="md-social__link" href="https://t.me/sem_k32" rel="noopener" target="_blank" title="Telegram account">
<svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 7.0.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M256 8a248 248 0 1 0 0 496 248 248 0 1 0 0-496m115 168.7c-3.7 39.2-19.9 134.4-28.1 178.3-3.5 18.6-10.3 24.8-16.9 25.4-14.4 1.3-25.3-9.5-39.3-18.7-21.8-14.3-34.2-23.2-55.3-37.2-24.5-16.1-8.6-25 5.3-39.5 3.7-3.8 67.1-61.5 68.3-66.7.2-.7.3-3.1-1.2-4.4s-3.6-.8-5.1-.5c-2.2.5-37.1 23.5-104.6 69.1-9.9 6.8-18.9 10.1-26.9 9.9-8.9-.2-25.9-5-38.6-9.1-15.5-5-27.9-7.7-26.8-16.3.6-4.5 6.7-9 18.4-13.7 72.3-31.5 120.5-52.3 144.6-62.3 68.9-28.6 83.2-33.6 92.5-33.8 2.1 0 6.6.5 9.6 2.9 2 1.7 3.2 4.1 3.5 6.7.5 3.2.6 6.5.4 9.8z"></path></svg>
</a>
<a class="md-social__link" href="mailto:semkin.ki32@gmail.com" rel="noopener" target="_blank" title="Email">
<svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 7.0.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M48 64C21.5 64 0 85.5 0 112c0 15.1 7.1 29.3 19.2 38.4l208 156a48 48 0 0 0 57.6 0l208-156c12.1-9.1 19.2-23.3 19.2-38.4 0-26.5-21.5-48-48-48zM0 196v188c0 35.3 28.7 64 64 64h384c35.3 0 64-28.7 64-64V196L313.6 344.8c-34.1 25.6-81.1 25.6-115.2 0z"></path></svg>
</a>
</div>
</div>
</div>
</footer>
</div>
<div class="md-dialog" data-md-component="dialog">
<div class="md-dialog__inner md-typeset"></div>
</div>
<script id="__config" type="application/json">{"base": "../../../..", "features": [], "search": "../../../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
<script src="../../../../assets/javascripts/bundle.f55a23d4.min.js"></script>
<script src="../../../../javascripts/katex.js"></script>
<script src="https://unpkg.com/katex@0/dist/katex.min.js"></script>
<script src="https://unpkg.com/katex@0/dist/contrib/auto-render.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_SVG"></script>
<span hidden="True" id="default-template-settings">{"font.color": "#2a3f5f", "paper_bgcolor": "rgba(0,0,0,0)", "plot_bgcolor": "#E5ECF6", "polar.bgcolor": "#E5ECF6", "polar.angularaxis.gridcolor": "white", "polar.angularaxis.linecolor": "white", "polar.radialaxis.gridcolor": "white", "polar.radialaxis.linecolor": "white", "ternary.bgcolor": "#E5ECF6", "ternary.aaxis.gridcolor": "white", "ternary.aaxis.linecolor": "white", "ternary.baxis.gridcolor": "white", "ternary.baxis.linecolor": "white", "ternary.caxis.gridcolor": "white", "ternary.caxis.linecolor": "white", "xaxis.gridcolor": "white", "xaxis.linecolor": "white", "xaxis.zerolinecolor": "white", "yaxis.gridcolor": "white", "yaxis.linecolor": "white", "yaxis.zerolinecolor": "white", "scene.xaxis.backgroundcolor": "#E5ECF6", "scene.xaxis.gridcolor": "white", "scene.xaxis.linecolor": "white", "scene.xaxis.zerolinecolor": "white", "scene.yaxis.backgroundcolor": "#E5ECF6", "scene.yaxis.gridcolor": "white", "scene.yaxis.linecolor": "white", "scene.yaxis.zerolinecolor": "white", "scene.zaxis.backgroundcolor": "#E5ECF6", "scene.zaxis.gridcolor": "white", "scene.zaxis.linecolor": "white", "scene.zaxis.zerolinecolor": "white", "shapedefaults.line.color": "#2a3f5f", "annotationdefaults.arrowcolor": "#2a3f5f", "geo.bgcolor": "white", "geo.landcolor": "#E5ECF6", "geo.subunitcolor": "white", "geo.lakecolor": "white", "mapbox.style": "light"}</span><span hidden="True" id="slate-template-settings">{"font.color": "#f2f5fa", "paper_bgcolor": "rgba(0,0,0,0)", "plot_bgcolor": "rgb(17,17,17)", "polar.bgcolor": "rgb(17,17,17)", "polar.angularaxis.gridcolor": "#506784", "polar.angularaxis.linecolor": "#506784", "polar.radialaxis.gridcolor": "#506784", "polar.radialaxis.linecolor": "#506784", "ternary.bgcolor": "rgb(17,17,17)", "ternary.aaxis.gridcolor": "#506784", "ternary.aaxis.linecolor": "#506784", "ternary.baxis.gridcolor": "#506784", "ternary.baxis.linecolor": "#506784", "ternary.caxis.gridcolor": "#506784", "ternary.caxis.linecolor": "#506784", "xaxis.gridcolor": "#283442", "xaxis.linecolor": "#506784", "xaxis.zerolinecolor": "#283442", "yaxis.gridcolor": "#283442", "yaxis.linecolor": "#506784", "yaxis.zerolinecolor": "#283442", "scene.xaxis.backgroundcolor": "rgb(17,17,17)", "scene.xaxis.gridcolor": "#506784", "scene.xaxis.linecolor": "#506784", "scene.xaxis.zerolinecolor": "#C8D4E3", "scene.yaxis.backgroundcolor": "rgb(17,17,17)", "scene.yaxis.gridcolor": "#506784", "scene.yaxis.linecolor": "#506784", "scene.yaxis.zerolinecolor": "#C8D4E3", "scene.zaxis.backgroundcolor": "rgb(17,17,17)", "scene.zaxis.gridcolor": "#506784", "scene.zaxis.linecolor": "#506784", "scene.zaxis.zerolinecolor": "#C8D4E3", "shapedefaults.line.color": "#f2f5fa", "annotationdefaults.arrowcolor": "#f2f5fa", "geo.bgcolor": "rgb(17,17,17)", "geo.landcolor": "rgb(17,17,17)", "geo.subunitcolor": "#506784", "geo.lakecolor": "rgb(17,17,17)", "mapbox.style": "dark"}</span><script src="../../../../assets/javascripts/mkdocs-plotly-plugin.js"></script></body>
</html>